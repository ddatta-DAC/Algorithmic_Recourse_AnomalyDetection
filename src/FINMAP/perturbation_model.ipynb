{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3ff91ea3-0a7d-44f0-8e18-03d36c1db90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from torch.nn import Module\n",
    "from torch.nn import functional as F\n",
    "from torch import LongTensor as LT\n",
    "from torch import FloatTensor as FT\n",
    "from torch import nn\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "import proxyClassifier\n",
    "from proxyClassifier import proxy_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9bd4df3-e47a-4f52-81c5-d623daa5e94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class gumbel(nn.Module):\n",
    "    def __init__(self, dim, tau):\n",
    "        super(gumbel, self).__init__()\n",
    "        self.layer = F.gumbel_softmax\n",
    "        self.size = dim\n",
    "        self.tau = tau\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer(\n",
    "            x, \n",
    "            self.tau\n",
    "        )\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a674f772-7ad9-4f10-bd55-5ed7c5a50e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class perturb_network(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        domain_dims: list = [], \n",
    "        layer_dims:list  = [32,256,128,128],\n",
    "        dropout_prob = 0.2,\n",
    "        gumbel_tau = 0.5\n",
    "    ):\n",
    "        super(perturb_network, self).__init__()\n",
    "        self.gumbel_tau = gumbel_tau\n",
    "        self.domain_dims = domain_dims\n",
    "        self.num_domains = len(domain_dims)\n",
    "        self.layer_dims = layer_dims\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.__build__()\n",
    "        return\n",
    "    \n",
    "    def __build__(self):\n",
    "        \"\"\"\n",
    "        Build the architecture\n",
    "        \"\"\"\n",
    "        emb_layer_dim = self.layer_dims[0]\n",
    "        # Create an embedding layer for each domain\n",
    "        embModule_list = []\n",
    "        for  dim in self.domain_dims:\n",
    "            embModule_list.append(nn.Embedding(dim, emb_layer_dim))\n",
    "        self.embModule_list = nn.ModuleList(embModule_list)   \n",
    "        \n",
    "        fcn_layers = []\n",
    "        dropout_prob = self.dropout_prob\n",
    "        num_layers = len(self.layer_dims)\n",
    "        inp_dim = emb_layer_dim * len(self.domain_dims)\n",
    "        for i in range(1, num_layers):\n",
    "            op_dim =  self.layer_dims[i]\n",
    "            fcn_layers.append(nn.Linear(inp_dim,op_dim))\n",
    "            fcn_layers.append(nn.Dropout(dropout_prob))\n",
    "            fcn_layers.append(nn.ReLU())\n",
    "            inp_dim = op_dim\n",
    "        self.fcn = nn.Sequential(*fcn_layers)\n",
    "        # Projection layer \n",
    "        self.projModule_list = []\n",
    "        for dim in self.domain_dims:\n",
    "            self.projModule_list.append(nn.Sequential(\n",
    "                nn.Linear(op_dim, dim),\n",
    "                gumbel(dim, self.gumbel_tau)\n",
    "            ))\n",
    "        self.projModule_list = nn.ModuleList(self.projModule_list)      \n",
    "        \n",
    "        return \n",
    "    \n",
    "    def forward(self, X):\n",
    "        emb = []\n",
    "        for i in range(self.num_domains):\n",
    "            r = self.embModule_list[i](X[:,i])\n",
    "            emb.append(r)\n",
    "        emb = torch.cat(emb, dim =-1)\n",
    "        x1 = self.fcn(emb)\n",
    "        x2 = []\n",
    "        for i in range(self.num_domains):\n",
    "            r = self.projModule_list[i](x1)\n",
    "            r = torch.argmax(r , dim=1, keepdims=True)\n",
    "            x2.append(r)\n",
    "        x2 = torch.cat(x2, dim=-1)\n",
    "        return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a1698e55-219e-45eb-8f3b-456b56dfcad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class perturb_clf(ClassifierMixin, BaseEstimator):\n",
    "    \"\"\"\n",
    "    Container for the proxy model \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        perturb_model: perturb_network,\n",
    "        clf_model: proxy_clf_network,\n",
    "        dataset :str = None,\n",
    "        batch_size: int = 512,\n",
    "        LR: float = 0.001,\n",
    "        eta:float = 2.0, # From the paper\n",
    "        device = torch.device(\"cpu\"),\n",
    "    ):\n",
    "        self.perturb_model = perturb_network\n",
    "        self.signature = 'proxy_{}'.format(dataset) \n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.LR = LR \n",
    "        self.clf_model = clf_model\n",
    "        self.eta = eta\n",
    "        return\n",
    "    \n",
    "    def calc_discrete_reg(self, X_data, X_pert):\n",
    "        diff = []\n",
    "        for idx in range(self.num_domains):\n",
    "            x1 = X_data[:,idx]\n",
    "            x2 = X_pert[:,idx]\n",
    "            _diff = torch.eq(x1, torch.x2).to(int)\n",
    "            diff.append(_diff)\n",
    "        diff = torch.cat(diff,dim=-1)\n",
    "        reg = self.eta * torch.mean(diff)\n",
    "        return reg\n",
    "    \n",
    "    def train(\n",
    "        self,\n",
    "        X : np.array, \n",
    "        Y : np.array, # Should be the inverted label ( 1 - f(x))\n",
    "        num_epochs:int = 50,\n",
    "        log_interval:int = 100\n",
    "    ):\n",
    "        self.perturb_model.train()\n",
    "        self.clf_model.eval()\n",
    "        self.perturb_model.to(self.device)\n",
    "        self.clf_model.to(self.device)\n",
    "        bs = self.batch_size\n",
    "        opt = torch.optim.Adam(list(self.perturb_model.parameters()), lr = self.LR)\n",
    "        num_batches = X.shape[0] // bs + 1\n",
    "        idx = np.arange(X.shape[0])\n",
    "        loss_values = []\n",
    "        clip_value = 5\n",
    "        # train model \n",
    "        for epoch in tqdm(range(num_epochs)):\n",
    "            np.random.shuffle(idx)\n",
    "            epoch_loss = []\n",
    "            for b in range(num_batches):\n",
    "                opt.zero_grad() \n",
    "                b_idx = idx[b*bs:(b+1)*bs]\n",
    "                x = LT(X[b_idx]).to(self.device) \n",
    "                pred_x = self.perturb_model(x)\n",
    "                \n",
    "                # pass this to classification model \n",
    "                pred_y = self.clf_model(\n",
    "                    pred_x\n",
    "                )\n",
    "                target_y = FT(Y[b_idx]).to(self.device)\n",
    "                # Calculate loss\n",
    "                loss = F.binary_cross_entropy(pred_y, target_y)\n",
    "                \n",
    "                # Add regulaization\n",
    "                # \\eta * 1( x_i != x_j )\n",
    "                reg = self.calc_discrete_reg()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), clip_value)\n",
    "                opt.step()\n",
    "                if b % log_interval == 0 :\n",
    "                    print('[Epoch] {}  | batch {} | Loss {:4f}'.format(epoch, b, loss.cpu().data.numpy()))\n",
    "                epoch_loss.append(loss.cpu().data.numpy())\n",
    "            epoch_loss = np.mean(epoch_loss)\n",
    "            loss_values.append(epoch_loss)\n",
    "        return  loss_values  \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Given X from data space ,\n",
    "        provide a perturbed instance\n",
    "        \"\"\"\n",
    "        self.clf_model.eval()\n",
    "        self.perturb_model.eval()\n",
    "        result = []\n",
    "        with torch.no_grad():\n",
    "            bs = self.batch_size\n",
    "            num_batches = X.shape[0] // bs + 1\n",
    "            idx = np.arange(X.shape[0])\n",
    "            for b in range(num_batches):\n",
    "                b_idx = idx[b*bs:(b+1)*bs]\n",
    "                x = LT(X[b_idx]).to(self.device)\n",
    "                pred_y = self.perturb_model(x)\n",
    "                pred_y = pred_y.cpu().data.numpy()\n",
    "                result.extend(pred_y)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d445ec72-e86b-4974-97e1-16fcf16c14f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
