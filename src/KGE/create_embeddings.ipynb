{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d54a7d7d-065d-43b5-8d8c-0e821251517b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import numpy as np\n",
    "sys.path.append('./..')\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import stellargraph\n",
    "from pathlib import Path\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph.mapper import *\n",
    "from stellargraph.layer import DistMult,regularizers\n",
    "from stellargraph import datasets, utils\n",
    "from tensorflow.keras import callbacks, optimizers, losses, metrics, regularizers, Model\n",
    "from collections import OrderedDict\n",
    "# from IPython.display import HTML\n",
    "import argparse\n",
    "\n",
    "DATA_DIR = None\n",
    "DIR = None\n",
    "id_col = 'PanjivaRecordID'\n",
    "CONFIG_FILE = 'config.yaml'\n",
    "KG_emb_dim = 64\n",
    "kg_train_numNegSamples = 10\n",
    "domain_dims = None\n",
    "KG_emb_save_dir = None\n",
    "KG_train_batchsize = 512\n",
    "KG_train_patience = 10\n",
    "KG_train_epochs = 100\n",
    "\n",
    "# ----------------------------------------------\n",
    "\n",
    "def setup_config(_DIR):\n",
    "    global DATA_DIR, DIR, KG_emb_dim, kg_train_num_neg_samples, domain_dims\n",
    "    global KG_emb_save_dir\n",
    "    global KG_train_epochs\n",
    "    global KG_train_patience\n",
    "    global KG_train_batchsize\n",
    "    DIR = _DIR\n",
    "    with open(CONFIG_FILE,'r') as fh:\n",
    "        config = yaml.safe_load(fh)\n",
    "    DATA_DIR = config['DATA_DIR']\n",
    "    KG_emb_dim = config['embedding_dimension']\n",
    "    kg_train_num_neg_samples  = config ['kg_train_num_neg_samples']\n",
    "    domain_dims = pd.read_csv( os.path.join(DATA_DIR, _DIR, 'data_dimensions.csv'), index_col= None)\n",
    "    KG_emb_save_dir = os.path.join(config['kg_emb_save_dir'], _DIR)\n",
    "    KG_train_epochs = config['kg_train_epochs']\n",
    "    KG_train_patience = config['kg_train_epochs']\n",
    "    KG_train_batchsize = config['kg_train_batch_size']\n",
    "    Path(os.path.join(KG_emb_save_dir, _DIR)).mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    return \n",
    "\n",
    "\n",
    "\n",
    "def get_graphTrainingData():\n",
    "    global DATA_DIR, DIR, id_col\n",
    "    with open('metapaths.txt','r') as fh:\n",
    "        mp = fh.readlines()\n",
    "    mp = [ _.strip('\\n') for _ in mp]\n",
    "    mp = [ _.split(',') for _ in mp]\n",
    "    # Create data\n",
    "    df_data_file = os.path.join(DATA_DIR, DIR, 'train_data.csv')\n",
    "    df = pd.read_csv(df_data_file, index_col = None)\n",
    "\n",
    "    try:\n",
    "        del df[id_col]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    df_named = df.copy(deep=True)\n",
    "    columns = list(df_named.columns)\n",
    "\n",
    "    for col in columns:\n",
    "        df_named[col] = df_named[col].apply(lambda x : col+'_'+ str(x))\n",
    "\n",
    "    relationships = set()\n",
    "    for _mp in mp:\n",
    "        for i in range(len(_mp)-1):\n",
    "            relationships = relationships.union( [(_mp[i],_mp[i+1])])\n",
    "\n",
    "\n",
    "    edge_data_wLabels = pd.DataFrame(columns=['source','label', 'target'])\n",
    "    for relation in relationships:\n",
    "        _columns = list(relation)\n",
    "        df_tmp = df_named[_columns]\n",
    "        df_tmp = df_tmp.rename(columns = {_columns[0]:'source', _columns[1]:'target'})\n",
    "        df_tmp.loc[:,'label'] = '_'.join( sorted([_columns[0], _columns[1]]))\n",
    "        df_w = df_tmp.groupby(['source', 'target']).size().reset_index(name='weight')\n",
    "        df_tmp = df_tmp.merge(df_w, on =['source','target'], how='inner')\n",
    "        edge_data_wLabels = edge_data_wLabels.append(df_tmp,ignore_index=True)\n",
    "        edge_data_wLabels = edge_data_wLabels.drop_duplicates(subset =['source', 'target']).reset_index(drop=True)\n",
    "    node_dict = {}\n",
    "    for column in list(df_named.columns):\n",
    "        nodes = list(sorted(set(df_named[column])))\n",
    "        node_dict[column] = pd.DataFrame( None, index= nodes)\n",
    "    return node_dict, edge_data_wLabels\n",
    "\n",
    "'''\n",
    "Main function to train the model\n",
    "'''\n",
    "\n",
    "def train_model():\n",
    "    global KG_train_epochs\n",
    "    global KG_train_patience\n",
    "    global KG_emb_dim\n",
    "    global KG_emb_save_dir\n",
    "    global KG_train_batchsize\n",
    "    \n",
    "    node_dict, edge_data_wLabels = get_graphTrainingData()\n",
    "    \n",
    "    sg = StellarGraph(\n",
    "        node_dict, \n",
    "        edge_data_wLabels,\n",
    "        edge_type_column=\"label\"\n",
    "    )\n",
    "\n",
    "    _gen = KGTripleGenerator(\n",
    "        sg,\n",
    "        batch_size=KG_train_batchsize  # ~10 batches per epoch\n",
    "    )\n",
    "\n",
    "    distmult = DistMult(\n",
    "        _gen,\n",
    "        embedding_dimension=KG_emb_dim,\n",
    "        embeddings_regularizer=regularizers.l2(1e-7),\n",
    "    )\n",
    "\n",
    "    _inp, _out = distmult.in_out_tensors()\n",
    "    _model = Model(\n",
    "        inputs=_inp, \n",
    "        outputs=_out\n",
    "    )\n",
    "    _model.compile(\n",
    "        optimizer=optimizers.Adam(lr=0.001),\n",
    "        loss=losses.BinaryCrossentropy(from_logits=True),\n",
    "        metrics=[metrics.BinaryAccuracy(threshold=0.0)],\n",
    "    )\n",
    "\n",
    "\n",
    "    _train_gen = _gen.flow(\n",
    "        edge_data_wLabels, \n",
    "        negative_samples=kg_train_num_neg_samples, \n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    earlyStop_callback = callbacks.EarlyStopping(\n",
    "        monitor=\"binary_accuracy\", \n",
    "        patience=KG_train_patience\n",
    "    )\n",
    "\n",
    "    _model.fit(\n",
    "        _train_gen,\n",
    "        epochs=KG_train_epochs,\n",
    "        callbacks = [earlyStop_callback],\n",
    "        verbose=1,\n",
    "    )\n",
    "    '''\n",
    "    Obtain embeddings of node and relations\n",
    "    '''\n",
    "\n",
    "    node_embeddings = distmult.embeddings()[0]\n",
    "    relation_embeddings = distmult.embeddings()[1]\n",
    "    domains_list = list(domain_dims['column'].values)\n",
    "    node_emb_dict = OrderedDict( { _ : OrderedDict({}) for _ in domains_list }  )\n",
    "    relation_emb_dict = {}\n",
    "\n",
    "    for entity,emb in zip(list(sg.nodes()),node_embeddings):\n",
    "        dom, e = entity.split('_')\n",
    "        e = int(e)\n",
    "        node_emb_dict[dom][e] = emb\n",
    "\n",
    "\n",
    "    for idx,e_type in enumerate(sg.edge_types,0):\n",
    "        relation_emb_dict[e_type] = relation_embeddings[idx]\n",
    "\n",
    "    '''\n",
    "    Save KGE embeddings\n",
    "    '''\n",
    "    nodeEmb_saveFile_name = 'KG_DM_nodeEmb_{}.pkl'.format(KG_emb_dim)\n",
    "    edgeEmb_saveFile_name = 'KG_DM_edgeEmb_{}.pkl'.format(KG_emb_dim)\n",
    "\n",
    "    with open(os.path.join(KG_emb_save_dir, nodeEmb_saveFile_name), 'wb') as fh:\n",
    "        pickle.dump(node_emb_dict, fh, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    with open(os.path.join(KG_emb_save_dir, edgeEmb_saveFile_name), 'wb') as fh:\n",
    "        pickle.dump(relation_emb_dict, fh, pickle.HIGHEST_PROTOCOL)\n",
    "    print('[INFO]  Saved embeddings at :',  os.path.join(KG_emb_save_dir, edgeEmb_saveFile_name), os.path.join(KG_emb_save_dir, edgeEmb_saveFile_name))\n",
    "    return\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "parser = argparse.ArgumentParser(description='Generate anomalies')\n",
    "parser.add_argument('--dir', type = str, help='Which dataset ? us__import{1,2...}' )\n",
    "args = parser.parse_args()\n",
    "DIR = args.dir\n",
    "\n",
    "setup_config(DIR)\n",
    "train_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fec8659-fa27-49d9-b473-f1a2e4e24fef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcb7c8f-2c5d-4b4e-b8c5-950c511a6dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa2a7c4-2804-4d8b-b64d-e79cc67a1d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
